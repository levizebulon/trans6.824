# Mapreduce: 大规模集群上的简化处理 #

## 摘要 ##

MapReduce 是一个处理和生成大规模数据集的编程模型和相关实现。用户指定处理键/值对以生成一组中间键/值对的map函数，以及指定归纳与同一中间键关联的所有中间值的reduce函数。 如本文所示，许多现实世界中的任务在此模型中均可表达。

以这种函数风格编写的程序会自动并行化，并在大型商品计算机集群上执行。 运行时系统负责划分输入数据，安排程序在一组机器上的执行，处理机器故障以及管理所需的机器间通信的细节。 这使得没有并行和分布式系统经验的程序员可以轻松地利用大型分布式系统的资源。我们的MapReduce实现在大型商用机器上运行，并且具有高度可扩展性：典型的MapReduce计算过程可处理数兆兆字节的数据 在数千台机器上。 程序员发现该系统易于使用：每天执行数百个MapReduce程序，每天在Google集群上执行多达一千个MapReduce作业。

## 1 概要 ##
在过去的五年中，Google的作者和其他许多人已经实施了数百种特殊用途的计算，可以处理大量原始数据（例如抓取的文档，Web请求日志等），以计算各种衍生数据，例如反向索引， Web文档的图形结构的各种表示形式，每个主机抓取的页面数的摘要，给定日期中最频繁查询的集合等。大多数此类计算在概念上很简单。但是，输入数据通常很大，必须在数百或数千台计算机上分布计算，才能在合理的时间内完成计算。有关如何对计算进行同等化，分配数据以及处理失败的问题，旨在使原始的简单计算难以用大量复杂的代码来掩盖，以解决这些问题。针对这种复杂性，我们设计了一种新的抽象方法我们来表达我们试图执行的简单计算，但是在库中隐藏了并行化，容错，数据分发和负载平衡的混乱细节。 Lisp 和许多其他功能语言中的mapandreduce原语启发了我们的抽象。我们意识到，我们的大多数计算都涉及对输入中的每个逻辑“记录”应用加乘运算，以便计算出一组中间键/值对，然后对所有共享同一键的值应用演绎运算，以便将派生结果组合在一起。适当的数据。我们使用具有用户指定的映射和归约运算的功能模型，使我们能够轻松地对大型计算进行并行处理，并使用重新执行作为容错的主要机制。这项工作的主要贡献是一个简单而强大的界面，该界面可实现自动大规模计算的并行化和分布，以及该接口的实现，可以在大型商用PC集群上实现高性能。第二部分介绍了基本的编程模型，并给出了几个示例。第3节描述了针对我们基于集群的计算环境量身定制的MapReduce接口的实现。第4节描述了一些有用的编程模型改进。第五部分对我们执行各种任务的性能进行了评估。第6部分探讨了Google内部MapReduce的用法，包括我们使用它作为重写生产索引系统基础的经验。第7节讨论相关和未来的工作

## 2 编程模型 ##

该计算采用一组输入键/值对，并产生一组输出键/值对。 MapReduce库的用户将计算表示为两个功能：Map和Reduce。由用户编写的Map接受一个输入对，并产生一组中间键/值对。 MapReduce库将与同一中间键 $I$ 关联的所有中间值分组在一起，然后将它们传递给Reduce函数。Reduce函数也由用户编写，可以接受中间键I和该键的一组值。 将这些值合并在一起以形成可能较小的一组值。 通常，每个Reduce调用仅产生零个或一个输出值。 中间值通过迭代器提供给用户的reduce函数。 这使我们能够处理太大而无法容纳在内存中的值列表。

### 2.1 样例 ##

考虑对大量文档中每个单词的出现次数进行计数的问题。 用户将编写类似于下面的伪代码的代码：

~~~bash
map(String key, String value):
    // key: document name
    // value: document contents
    for each word w in value:
        EmitIntermediate(w, "1");
reduce(String key, Iterator values):
    // key: a word
    // values: a list of counts
    int result = 0;
    for each v in values:
        result += ParseInt(v);
    Emit(AsString(result));
~~~